{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rating_webscraper_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkKLZ1_1Y-CH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "6b0bc8e3-8e9d-4ceb-d1f0-4ec00f2b85b8"
      },
      "source": [
        "pip install google_play_scraper"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_play_scraper\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/b5/560ff4472c33285b91af435815c7e9cff4c2acc01620fd0f80a59d71e345/google-play-scraper-0.1.1.tar.gz (49kB)\n",
            "\r\u001b[K     |██████▋                         | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: google-play-scraper\n",
            "  Building wheel for google-play-scraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-play-scraper: filename=google_play_scraper-0.1.1-cp36-none-any.whl size=22260 sha256=841700abfdb33d0c59431319ca31ecc23a76ae84c134a3a32c5e9b320e166365\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/1f/71/e2b30aab85297ad6dd2e3049587a6763cfb7e803a0b76d982e\n",
            "Successfully built google-play-scraper\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P8u0RKBvBGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62fce046-989f-4517-884f-11d55f1abdab"
      },
      "source": [
        "import os\n",
        "\n",
        "# verifying and removing the file, if exists from google drive\n",
        "\n",
        "if os.path.exists(\"app_review.csv\"):\n",
        "  os.remove(\"app_review.csv\")\n",
        "  print(\"The file is deleted.\")\n",
        "else:\n",
        "  print(\"The file does not exist.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file does not exist.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc6ToXPZ_xsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "from google_play_scraper import Sort, reviews\n",
        "import re\n",
        "import sys\n",
        "\n",
        "\n",
        "def web_scrapping(x):\n",
        "  for i in range (x,x+200):\n",
        "    try:\n",
        "      result, continuation_token = reviews(\n",
        "        'com.google.android.apps.youtube.kids',\n",
        "        lang='en', # defaults to 'en'\n",
        "        country='us', # defaults to 'us'\n",
        "        sort=Sort.RATING, # None, defaults to Sort.MOST_RELEVANT\n",
        "        count=i, # defaults to 100\n",
        "        filter_score_with=5\n",
        "      )\n",
        "\n",
        "      # If we pass 'continuation_token' as an argument to the reviews function at this point,\n",
        "      # it will crawl the items after \"i-th\" review item.\n",
        "          \n",
        "      result, _ = reviews(\n",
        "        'com.google.android.apps.youtube.kids',\n",
        "        continuation_token=continuation_token # defaults to None(load from the beginning)\n",
        "      )\n",
        "\n",
        "      # remove unicode characters from data\n",
        "      txt = str(result)\n",
        "      txt = remove_emoji(txt)\n",
        "      txt = re.sub(\"'\",\"\",txt)\n",
        "      txt = re.sub(\"\\\"\",\"\",txt)\n",
        "      txt = re.sub(\"#\",\"\",txt)\n",
        "      user = txt.split('userName: ')[1].split(', userImage')[0]\n",
        "      rating = txt.split('score: ')[1].split(', thumbsUpCount')[0]\n",
        "      upvote = txt.split('thumbsUpCount: ')[1].split(', reviewCreatedVersion')[0]\n",
        "      datetime = re.search('datetime.datetime\\((.+?)\\),', txt).group(1)\n",
        "      datetime = re.sub(\", \",\",\",datetime)\n",
        "      review = re.search('content: (.+?), score', txt).group(1)\n",
        "      review = re.sub(\"!\",\"\",review)\n",
        "      review = re.sub(\",\",\"\",review)\n",
        "      review = \"'\"+review+\"'\"\n",
        "\n",
        "      print(\"i : \",i)\n",
        "      print(user)\n",
        "      print(datetime)\n",
        "      print(rating)\n",
        "      print(upvote)\n",
        "      print(review)\n",
        "\n",
        "      # created and opened file in append mode\n",
        "      file = open('app_review.csv','a')\n",
        "      file.write(user+', '+rating+', '+upvote+', '+review+', '+datetime+'\\n')\n",
        "\n",
        "    finally:\n",
        "          file.close()\n",
        "  return\n",
        "\n",
        "# applying multi-processing to extract reviews 5x faster - p1, p2, p3, p4, p5\n",
        "# each child process will extract 100 reviews\n",
        "# we can add as many child processes as we like.\n",
        "\n",
        "i=1\n",
        "p1 = multiprocessing.Process(target=web_scrapping,args=[i])\n",
        "p2 = multiprocessing.Process(target=web_scrapping,args=[i+100])\n",
        "p3 = multiprocessing.Process(target=web_scrapping,args=[i+200])\n",
        "p4 = multiprocessing.Process(target=web_scrapping,args=[i+300])\n",
        "p5 = multiprocessing.Process(target=web_scrapping,args=[i+400])\n",
        "\n",
        "\n",
        "# starting the child processes\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "p3.start()\n",
        "p4.start()\n",
        "p5.start()\n",
        "\n",
        "\n",
        "# joining the child processes to parent process\n",
        "\n",
        "p1.join()\n",
        "p2.join()\n",
        "p3.join()\n",
        "p4.join()\n",
        "p5.join()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK8frf_eFJsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloading the .csv file into local drive\n",
        "\n",
        "from google.colab import files\n",
        "files.download('app_review.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}